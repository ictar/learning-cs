原文：[scheduling-in-go-part2](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html)

---


### 前言

这是一个包含三个部分的系列文，它将向你提供对 Go 调度器背后对机制和语义的理解。这是第二篇。本文着重于 Go 调度器。

该序列文三个部分的索引：
1) [Go 调度（第一部分）：OS 调度器](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html)  
2) [Go 调度（第二部分）：Go 调度器](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html)  
3) [Go 调度（第三部分）：并发](https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html)


### 介绍

在该调度系列文的[第一部分](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html)，我解释了操作系统调度器的一些方面，我认为这些方面对于理解和欣赏 Go 调度器的语义很重要。在这篇文章中，我将在语义层面上解释 Go 调度器的工作方式，并着重于高层次的行为。Go 调度器是一个复杂的系统，而少量的机器细节并不重要。重要的是要有一个好的模型来说明事情的工作方式和行为方式。这将使你做出更好的工程决策。

### 程序启动

当 Go 程序启动时，会为主机上识别的每一个虚拟内核提供一个逻辑处理器（P）。如果你有一个处理器，它每个物理核心都有多个硬件线程（[Hyper-Threading](https://en.wikipedia.org/wiki/Hyper-threading)，超线程），那么对于你的 Go 程序来说，每个硬件线程将展示为一个虚拟内核。为了更好地理解这一点，请看我的 MacBook Pro 的系统报告。

**图 1**  
![](https://www.ardanlabs.com/images/goinggo/94_figure1.png)

可以看到，我有一个具有 4 个物理内核的处理器。该报告未公开的是我每个物理内核的硬件线程数。Intel Core i7 处理器具有 Hyper-Threading 功能, 这意味着每个物理内核具有 2 个硬件线程。这将向 Go 程序报告有 8 个虚拟内核可用于并行执行操作系统线程。

要对此进行测试，考虑下面的程序：

**清单 1**
    
```golang    
package main

import (
  "fmt"
  "runtime"
)

func main() {

    // NumCPU 返回当前进程
    // 可用的逻辑 CPU 数目。
    fmt.Println(runtime.NumCPU())
}
```    

当我在本地运行这个程序时，NumCPU() 函数调用的结果将是 8。我在本地运行的任何 Go 程序将获得 8 个 P。

每个 P 都分配有一个操作系统线程（“M”）。“M” 表示机器。该线程仍然由操作系统管理，并且操作系统仍然负责将线程调度到内核上执行，正如[上一篇文章](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html)中解释的那样。这意味着，当我在我的电脑上运行 Go 程序时，我有 8 个可以工作的线程，每个线程单独附加在 P 上。

每个 Go 程序还会获得一个初始的 Goroutine ("G")，它是 Go 程序的执行路径。Goroutine 本质上是一个[协程（Coroutine）](https://en.wikipedia.org/wiki/Coroutine)，但这里是 Go，所以我们将字母 “C” 替换为 “G”，于是就得到了 Goroutine 这个词。你可以将 Goroutine 视为应用层线程，在很多方面，它们都类似于操作系统线程。就想操作系统线程是在内核上进行上下文切换的，Goroutine 则是在 M 上进行上下文切换。

拼图的最后一片是运行队列。Go 调度器中有两个不同的运行队列：全局运行队列（GRQ）和本地运行队列（LRQ）。每个 P 都有一个 LRQ，负责管理分配到 P 的上下文中执行的 Goroutine。这些 Goroutine 在分配给 P 的 M 上轮流进行上下文切换。GRQ 用于尚未分配给 P 的 Goroutine。有一个过程会将 Goroutine 从 GRQ 转移到 LRQ。我们稍后会讨论。

图 2 提供了这些组件的示意图。

**图 2**  
![](https://www.ardanlabs.com/images/goinggo/94_figure2.png)

### 协作式调度器

正如我们在第一篇文章中讨论的那样，操作系统调度器是一个抢占式调度程序。从本质上讲，这意味着你无法预测任意给定时间点调度器的行为。内核进行决策，而一切都是不确定的。运行在操作系统之上的应用无法通过调度来控制内核内部发生的事情，除非它们利用了诸如 [atomic](https://en.wikipedia.org/wiki/Linearizability) 指令和 [mutex](https://en.wikipedia.org/wiki/Lock_\(computer_science\)) 调用之类的同步原语。

Go 调度器是 Go 运行时的一部分，而 Go 运行时已经内置到你的应用中。这意味着，Go 调度器运行在内核之上的[用户空间](https://en.wikipedia.org/wiki/User_space)中。Go 调度器的当前实现不是抢占式调度器，而是[协作式](https://en.wikipedia.org/wiki/Cooperative_multitasking)调度器。调度器是协作式的意味着调度器需要定义良好的用户空间事件，这些事件在代码中的安全点处发生，以进行调度决策。

Go 协作式调度器的优异之处在于，它看起来并且感觉上是抢占式的。你无法预测 Go 调度器的行为。这是因为该协作式调度器的决策权不在开发者手中，而在 Go 运行时。将 Go 调度器视为抢占式调度器很重要，并且由于调度器是不确定的，因此这并不是一件容易的事情。

### Goroutine 状态

就像线程一样，Goroutine 具有相同的三种高级状态。这些状态决定了 Go 调度器在任何给定的 Goroutine 中扮演的角色。Goroutine 可以处于以下三种状态：_等待态_、_可运行态_ 或者 _执行态_。

**等待态**：这意味着 Goroutine 已停止，正在等待某些东西才能继续执行。这可能是由于等待操作系统（系统调用）或者同步调用（原子和互斥操作）之类的原因。这些类型的[延迟](https://en.wikipedia.org/wiki/Latency_\(engineering\))是导致性能下降的根本原因。

**可运行态**：这意味着 Goroutine 需要 M 来执行其分配的指令。如果你有很多需要 M 的 Goroutine，那么 Goroutine 必须等待更长的时间才能在 M 上执行。此外，随着更多的 Goroutine 抢夺执行时间，任何给定的 Goroutine 所获得的执行时间都将缩短。这种类型的调度等待时间也可能是性能下降的原因。

**执行态**：这意味着 Goroutine 已经在 M 上并且正在执行指令。与应用相关的工作已经在完成。这就是每个人都想要的。

### 上下文切换

Go 调度器需要定义良好的用户态事件，它们发生在代码中的安全点处，以便进行上下文切换。这些事件和安全点体现在函数调用中。函数调用对 Go 调度器的健康运行至关重要。现今（使用 Go 1.11 或更低版本），如果你运行任何不会进行函数调用的紧密循环，则会引发调度器和垃圾收集的延迟。在合理的时间范围内进行函数调用至关重要。

_注意：有一个对于 1.12 的[建议](https://github.com/golang/go/issues/24543) 是在 Go 调度器中应用非协作式抢占技术，以允许对紧密循环进行抢占。它已经被接收（译注：但是 Go 1.12 版本尚未实现，可以持续关注下。）。_

Go 程序中发生的四类事件会让调度器进行调度决策。这并不是说它总是会在这些事件之一中发生。而是意味着调度器有机会进行调度。

  * 关键字 `go` 的使用
  * 垃圾收集
  * 系统调用
  * 同步和编排



**关键字 `go` 的使用**

关键字 `go` 是创建 Goroutine 的方式。一旦创建了一个新的 Goroutine，就会给调度器一次进行调度决策的机会。

**垃圾收集**

由于 GC 是使用自己的 Goroutine 集来运行的，因此，这些 Goroutine 需要 M 的时间片才能运行。这导致 GC 造成了大量的调度混乱。但是，调度器非常明白 Goroutine 在干嘛，因此它会利用它所知道的信息做出明智的决策。一个明智的决策是，在 GC 过程中，用不需要访问堆的 Goroutine 上下文切换下想要访问堆的 Goroutine。当 GC 运行时，会进行大量的调度决策。

**系统调用**

如果 Goroutine 进行了导致阻塞 M 的系统调用，那么，有时候调度器能够将这个 Goroutine 上下文切换下 M，并将另外一个新的 Goroutine 上下文切换到同一个 M。但是，有时候需要用新的 M 来保持执行 P 中排队的 Goroutine。下一节将详细说明其工作方式。

**同步和编排**

如果原子、互斥或者通道操作会阻塞 Goroutine，那么调度器可以上下文切换一个新的 Goroutine 来运行。一旦这个 Goroutine 可以再次运行，就会将其重新入队，并最终会上下文切换回 M。

### 异步系统调用

如果你运行程序的操作系统能够异步处理系统调用，那么可以使用[网络轮询器（network poller）](https://golang.org/src/runtime/netpoll.go)来更有效地处理系统调用。这可以通过使用各个操作系统中的 kqueue (MacOS)、epoll (Linux) 或者 iocp (Windows) 来完成。

我们现今使用的许多操作系统都可以异步处理基于网络的系统调用。这就是为什么它被称之为网络轮询器的原因，因为它的主要用途是处理网络操作。通过使用网络轮询器进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用的时候阻塞 M。这有助于 M 可以继续执行 P 的本地运行队列中的其他 Goroutine，而无需创建新的 M。这有助于减少操作系统傻姑娘的调度负载。

了解其工作方式的最佳方法是运行一个示例。

**图 3**  
![](https://www.ardanlabs.com/images/goinggo/94_figure3.png)

图 3 显示了基本调度图。Goroutine-1 正在 M 上运行，LRQ 中还有 3 个 Goroutine 等待获得 M 的运行时间。网络轮询器空闲，啥事都没有。

**图 4**  
![](https://www.ardanlabs.com/images/goinggo/94_figure4.png)

在图 4 中，Goroutine-1 想要进行网络系统调用，因此，Goroutine-1 被移到了网络轮询器，并且异步网络系统调用也得到了处理。一旦 Goroutine-1 移至网络轮询器，M 就可以执行 LRQ 中另一个 Goroutine。在这种情况下，Goroutine-2 被上下文切换至 M。

**图 5**  
![](https://www.ardanlabs.com/images/goinggo/94_figure5.png)

在图 5 中，网络轮询器完成了异步网络系统调用，并且 Goroutine-1 被移回到了 P 的 LRQ 中。一旦 Goroutine-1 可以被上下文切换回 M，它负责的 Go 相关的代码就可以再次执行。这里最大的好处是，执行网络系统调用不需要额外的 M。网络轮询器自带一个操作系统线程，并且它在处理一个有效的事件循环。

### 同步系统调用

当 Goroutine 想要进行无法异步完成的系统调用时，会发生什么呢？在这种情况下，无法使用网络轮询器，因此 Goroutine 进行的系统调用将会阻塞 M。这很不幸，但是没有办法阻止。无法异步完成的系统调用的一个例子是，基于文件的系统调用。如果你使用 CGO，那么可能存在这样的场景：调用 C 函数也会阻塞 M。

_注意：Windows 操作系统有能力异步进行基于文件的系统调用。从技术上讲，当运行在 Windows 时，可以使用网络轮询器。_

让我们看看在进行会阻塞 M 的同步系统调用（例如文件 I/O）时会发生什么。

**图 6**  
![](https://www.ardanlabs.com/images/goinggo/94_figure6.png)

图 6 再次显示我们的基本调度图，但是这一次，Goroutine-1 将要进行一次会阻塞 M1 的系统调用。

**图 7**  
![](https://www.ardanlabs.com/images/goinggo/94_figure7.png)

在图 7 中，调度器能够识别到 Goroutine-1 导致了 M 被阻塞。此时，调度器将 M1 从 P 上解绑，与此同时，阻塞的 Goroutine-1 仍然绑定在 M 上。然后，调度器让一个新的线程，也就是 M2，来服务 P。这个时候，可以从 LRQ 选择 Goroutine-2，然后将其上下文切换到 M2。如果在前面的交换中已经存在了一个 M，那么这种转换会更快，因为不必创建一个新的 M。

**图 8**  
![](https://www.ardanlabs.com/images/goinggo/94_figure8.png)

在图 8 中，Goroutine-1 进行的那次阻塞的系统调用完成了。此时，Goroutine-1 可以回到 LRQ，并且重新被 P 所服务。然后 M1 会被放置在一旁，以备后续相同的场景再次发生。

### 工作窃取（Work Stealing）

调度器的另一个方面是，它是一个工作窃取式调度器。在一些方面，这有助于高效调度。举例来说，你最不想看到的就是 M 变成等待态，因为一旦这种情况发生了，操作系统将会把这个 M 上下文切换下内核。这意味着，P 什么工作都完成不了（即使此时还有可运行态的 Goroutine），直到一个 M 被上下文切换回内核。工作窃取还有助于平衡所有 P 上的 Goroutine，这样的话，工作就能更好的分布并且更有效地完成。

让我们看一个例子。

**图 9**  
![](https://www.ardanlabs.com/images/goinggo/94_figure9.png)

在图 9 中，我们有一个多线程 Go 程序，并且有两个 P，每个 P 服务四个 Goroutine，同时，在 GRQ 中还有一个 Goroutine。如果其中一个 P 快速地服务完它所有的 Goroutine 的话，会发生什么呢？

**图 10**  
![](https://www.ardanlabs.com/images/goinggo/94_figure10.png)

在图 10 中，P1 没有更多 Goroutine 可以执行了。但还有处在可运行态的 Goroutine，它们位于 P2 的 LRQ 以及 GRQ 中。这就是 P1 需要窃取工作的时候了。[窃取工作](https://golang.org/src/runtime/proc.go)的规则如下。

**清单 2**
    
```golang    
runtime.schedule() {
    // 只有 1/61 的时间，检查全局运行队列找到一个 G。
    // 如果找不到，则检查本地运行队列。
    // 如果找不到，
    //     尝试从其他 P 那里窃取。
    //     如果没有，检查全局可运行队列。
    //     如果没找到，轮询网络。
}
```    

因此，基于清单 2 中的这些规则，P1 需要检查 P2 的 LRQ 中的 Goroutine，然后窃取它找到的一半 Goroutine。

**图 11**  
![](https://www.ardanlabs.com/images/goinggo/94_figure11.png)

在图 11 中，P1 从 P2 获取了一半的 Goroutine，现在，P1 可以执行这些 Goroutine 了。

如果 P2 服务完了它所有的 Goroutine，并且 P1 的 LRQ 也为空，会发生什么呢？

**图 12**  
![](https://www.ardanlabs.com/images/goinggo/94_figure12.png)

在图 12 中，P2 完成了它所有的工作，现在，它需要去窃取一些工作了。首先，它会看一下 P1 的 LRQ，此时，它找不到任何 Goroutine。接下来，它会检查 GRQ。在那里，它会找到 Goroutine-9。

**图 13**  
![](https://www.ardanlabs.com/images/goinggo/94_figure13.png)

在图 13 中，P2 从 GRQ 中窃取了 Goroutine-9，然后开始执行工作。所有这些工作窃取很棒的一点就是，它使得 M 都保持忙碌状态，不会变得空闲。这种工作窃取在内部被认为是旋转（spinning） M。这种旋转有其他的好处，JBD 在她的 [work-stealing](https://rakyll.org/scheduler/) 博文中对其进行了很好的解释。

### 实例

了解了机制和语义，我想向你展示所有这些是如何在一起让 Go 调度器随着时间的推移执行更多的工作的。想象一个用 C 写的多线程应用，其中，程序管理两个操作系统线程，这两个线程相互之间来回传递消息。

**图 14**  
![](https://www.ardanlabs.com/images/goinggo/94_figure14.png)

在图 14 中，两个线程在来回传递消息。线程 T1 被上下文切换到内核 C1，现在正在执行，这让 T1 可以发送消息给线程 T2。

_注意：如何传递消息并不重要。重要到是，随着业务流程到进行，线程到状态。_

**图 15**  
![](https://www.ardanlabs.com/images/goinggo/94_figure15.png)

在图 15 中，一旦 T1 结束发送消息，它现在就需要等待响应了。这会导致 T1 被上下文切换下 C1，并且进入等待态。一旦通知 T2 有消息，它就会进入可运行态。现在，操作系统可以进行上下文切换，让 T2 在内核上执行，也就是内核 C2。接下来，T2 处理消息，然后发送一个新到消息给 T1。

**图 16**  
![](https://www.ardanlabs.com/images/goinggo/94_figure16.png)

在图 16 中，当 T1 接收到 T2 发送的消息时，线程再次进行上下文切换。现在，T2从执行态上下文切换至等待态。而 T1 则从等待态上下文切换至可运行态，最终回到执行态，这使得 T1 可以处理并将新的消息发送回去。

所有这些上下文切换和状态改变都需要时间处理，这限制了工作的完成速度。每个上下文切换潜在的延迟约为 1000 纳秒。如果硬件每纳秒执行 12 条指令的话，那么在上下文切换期间，或多或少会有 12k 条指令没有执行。由于这些线程还在不同内核之间来回绑定，因此，由于高速缓存线未命中而导致的额外延迟的可能性也很高。

让我们看看同样的例子，不过这一次我们使用 Goroutine 和 Go 调度器来代替。

**图 17**  
![](https://www.ardanlabs.com/images/goinggo/94_figure17.png)

在图 17 中，有两个相互协调的 Goroutine 在相互传递消息。G1 上下文切换到 M1，而 M1 碰巧运行在内核 C1 上，这使得 G1 可以进行自己的工作。而 G1 的工作内容是发送消息到 G2。

**图 18**   　
![](https://www.ardanlabs.com/images/goinggo/94_figure18.png)

在图 18 中，一旦 G1 完成了消息发送，它现在就需要等待响应了。这会使 G1 上下文切换下 M1，然后进入等待态。一旦 G2 收到有关该消息的通知，它将进入可运行态。现在，Go 调度器可以进行上下文切换，并使 G2 在 M1 上执行，而 M1 仍然还运行在内核 C1 上。接下来，G2 处理消息，并将新消息发送回 G1。

**图 19**  
![](https://www.ardanlabs.com/images/goinggo/94_figure19.png)

在图 19 中，当 G1 接收到了 G2 发送的消息时，上下文切换再次发生。现在，G2 从执行态上下文切换至等待态，而 G1 则从等待态上下文切换至可运行态，最后回到执行态。这使得 G1 可以处理并发送新消息。

表面上似乎没有什么不同。无论是使用线程还是使用 Goroutine，所有相同的上下文切换和状态更改都会发生。乍看之下，使用线程和 Goroutine 之间的主要区别可能并不明显。

在使用 Goroutine 的情况下，所有处理都使用了相同的操作系统线程和内核。这意味着，从操作系统的角度来看，操作系统线程永远都不会进入等待态；而且还不止一次。结果，在使用线程时我们因为上下文切换而损耗的所有那些指令执行时间，在使用 Goroutine 的时候并不会损耗。

从本质上来讲，Go 在操作系统级别将 IO 密集型工作变成了计算密集型。由于所有的上下文切换都是在应用级别进行的，因此，在每次进行上下文切换的时候，我们不会损耗使用线程时损耗的（平均）大约 12k 条指令的执行时间。在 Go 中，这些相同的上下文切换将耗费大约 200 纳秒，或者约 2.4k 条指令执行时间。调度器还有助于提高高速缓存线效率和 [NUMA](http://frankdenneman.nl/2016/07/07/numa-deep-dive-part-1-uma-numa)。这就是为什么我们不需要比虚拟内核数更多的线程的原因。在 Go 中，随着时间的推移，是有可能完成更多的工作的，因为 Go 调度器会试图使用更少的线程，并且在每个线程上执行更多的操作，这有助于减少操作系统负载和硬件负载。

### 总结

Go 调度器在设计考虑到操作系统和硬件工作方式的复杂性方面确实非常了不起。在操作系统级别将 IO 密集型工作转变成计算密集型工作的能力，是我们随着时间的推移利用更多的 CPU 能力的巨大胜利。这就是为什么不需要比虚拟内核数更多的线程的原因。你可以合理地期望通过每个虚拟内核上的一个操作系统线程就可以完成所有的工作（包括计算密集型和 IO 密集型）。对于那些网络应用和其他那些不需要进行阻塞操作系统线程的系统调用的应用来说，这样做是可能的。

作为开发者，你仍然需要根据在处理的工作的类型，来了解你的应用在做什么。你无法创建无限数量的 Goroutine，并期望可以获得惊人的性能。少总是多的，但是有了这些对 Go 调度器语义的理解，你就可以做出更好的工程决策。在下一篇文章中，我将探讨一种思想：以保守的方式利用并发以获得更好的性能，同时仍然平衡代码复杂度。
